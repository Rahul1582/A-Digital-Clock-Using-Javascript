{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":3,"outputs":[{"output_type":"stream","text":"/kaggle/input/trump-tweets/trumptweets.csv\n/kaggle/input/trump-tweets/realdonaldtrump.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/trump-tweets/trumptweets.csv\")\ndf","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"                        id                                               link  \\\n0               1698308935  https://twitter.com/realDonaldTrump/status/169...   \n1               1701461182  https://twitter.com/realDonaldTrump/status/170...   \n2               1737479987  https://twitter.com/realDonaldTrump/status/173...   \n3               1741160716  https://twitter.com/realDonaldTrump/status/174...   \n4               1773561338  https://twitter.com/realDonaldTrump/status/177...   \n...                    ...                                                ...   \n41117  1218962544372670467  https://twitter.com/realDonaldTrump/status/121...   \n41118  1219004689716412416  https://twitter.com/realDonaldTrump/status/121...   \n41119  1219053709428248576  https://twitter.com/realDonaldTrump/status/121...   \n41120  1219066007731310593  https://twitter.com/realDonaldTrump/status/121...   \n41121  1219076533354037249  https://twitter.com/realDonaldTrump/status/121...   \n\n                                                 content                 date  \\\n0      Be sure to tune in and watch Donald Trump on L...  2009-05-04 20:54:25   \n1      Donald Trump will be appearing on The View tom...  2009-05-05 03:00:10   \n2      Donald Trump reads Top Ten Financial Tips on L...  2009-05-08 15:38:08   \n3      New Blog Post: Celebrity Apprentice Finale and...  2009-05-08 22:40:15   \n4      \"My persona will never be that of a wallflower...  2009-05-12 16:07:28   \n...                                                  ...                  ...   \n41117  I have never seen the Republican Party as Stro...  2020-01-19 19:24:52   \n41118  Now Mini Mike Bloomberg is critical of Jack Wi...  2020-01-19 22:12:20   \n41119  I was thrilled to be back in the Great State o...  2020-01-20 01:27:07   \n41120  “In the House, the President got less due proc...  2020-01-20 02:16:00   \n41121  A great show! Check it out tonight at 9pm. @ F...  2020-01-20 02:57:49   \n\n       retweets  favorites mentions hashtags  geo  \n0           500        868      NaN      NaN  NaN  \n1            33        273      NaN      NaN  NaN  \n2            12         18      NaN      NaN  NaN  \n3            11         24      NaN      NaN  NaN  \n4          1399       1965      NaN      NaN  NaN  \n...         ...        ...      ...      ...  ...  \n41117     32620     213817      NaN      NaN  NaN  \n41118     36239     149571      NaN      NaN  NaN  \n41119     16588      66944      NaN        #  NaN  \n41120     20599      81921    @ @ @      NaN  NaN  \n41121      7947      34902        @      NaN  NaN  \n\n[41122 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>link</th>\n      <th>content</th>\n      <th>date</th>\n      <th>retweets</th>\n      <th>favorites</th>\n      <th>mentions</th>\n      <th>hashtags</th>\n      <th>geo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1698308935</td>\n      <td>https://twitter.com/realDonaldTrump/status/169...</td>\n      <td>Be sure to tune in and watch Donald Trump on L...</td>\n      <td>2009-05-04 20:54:25</td>\n      <td>500</td>\n      <td>868</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1701461182</td>\n      <td>https://twitter.com/realDonaldTrump/status/170...</td>\n      <td>Donald Trump will be appearing on The View tom...</td>\n      <td>2009-05-05 03:00:10</td>\n      <td>33</td>\n      <td>273</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1737479987</td>\n      <td>https://twitter.com/realDonaldTrump/status/173...</td>\n      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n      <td>2009-05-08 15:38:08</td>\n      <td>12</td>\n      <td>18</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1741160716</td>\n      <td>https://twitter.com/realDonaldTrump/status/174...</td>\n      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n      <td>2009-05-08 22:40:15</td>\n      <td>11</td>\n      <td>24</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1773561338</td>\n      <td>https://twitter.com/realDonaldTrump/status/177...</td>\n      <td>\"My persona will never be that of a wallflower...</td>\n      <td>2009-05-12 16:07:28</td>\n      <td>1399</td>\n      <td>1965</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>41117</th>\n      <td>1218962544372670467</td>\n      <td>https://twitter.com/realDonaldTrump/status/121...</td>\n      <td>I have never seen the Republican Party as Stro...</td>\n      <td>2020-01-19 19:24:52</td>\n      <td>32620</td>\n      <td>213817</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>41118</th>\n      <td>1219004689716412416</td>\n      <td>https://twitter.com/realDonaldTrump/status/121...</td>\n      <td>Now Mini Mike Bloomberg is critical of Jack Wi...</td>\n      <td>2020-01-19 22:12:20</td>\n      <td>36239</td>\n      <td>149571</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>41119</th>\n      <td>1219053709428248576</td>\n      <td>https://twitter.com/realDonaldTrump/status/121...</td>\n      <td>I was thrilled to be back in the Great State o...</td>\n      <td>2020-01-20 01:27:07</td>\n      <td>16588</td>\n      <td>66944</td>\n      <td>NaN</td>\n      <td>#</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>41120</th>\n      <td>1219066007731310593</td>\n      <td>https://twitter.com/realDonaldTrump/status/121...</td>\n      <td>“In the House, the President got less due proc...</td>\n      <td>2020-01-20 02:16:00</td>\n      <td>20599</td>\n      <td>81921</td>\n      <td>@ @ @</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>41121</th>\n      <td>1219076533354037249</td>\n      <td>https://twitter.com/realDonaldTrump/status/121...</td>\n      <td>A great show! Check it out tonight at 9pm. @ F...</td>\n      <td>2020-01-20 02:57:49</td>\n      <td>7947</td>\n      <td>34902</td>\n      <td>@</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>41122 rows × 9 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer ","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clean=[]","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0, 15000):\n    review = re.sub('(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\"', ' ', df['content'][i])\n    review = review.lower()\n    review = review.split()\n    lm= WordNetLemmatizer() \n    review = [lm.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    clean.append(review)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['content'][0]","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"'Be sure to tune in and watch Donald Trump on Late Night with David Letterman as he presents the Top Ten List tonight!'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"clean[0]","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"'sure tune watch donald trump late night david letterman present top ten list tonight'"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# All the contents are cleaned.."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new=pd.DataFrame(df['content'][0:15000])\ndf_new","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"                                                 content\n0      Be sure to tune in and watch Donald Trump on L...\n1      Donald Trump will be appearing on The View tom...\n2      Donald Trump reads Top Ten Financial Tips on L...\n3      New Blog Post: Celebrity Apprentice Finale and...\n4      \"My persona will never be that of a wallflower...\n...                                                  ...\n14995  W/a newly expanded 27 holes of golfing, Trump ...\n14996  Thank you @ HauteLivingMag for naming @ TrumpD...\n14997  As I predicted, Obama already caught lying on ...\n14998  “Get to know yourself.You can’t improve upon s...\n14999  “Once you know you love your job, never stop a...\n\n[15000 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Be sure to tune in and watch Donald Trump on L...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Donald Trump will be appearing on The View tom...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\"My persona will never be that of a wallflower...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14995</th>\n      <td>W/a newly expanded 27 holes of golfing, Trump ...</td>\n    </tr>\n    <tr>\n      <th>14996</th>\n      <td>Thank you @ HauteLivingMag for naming @ TrumpD...</td>\n    </tr>\n    <tr>\n      <th>14997</th>\n      <td>As I predicted, Obama already caught lying on ...</td>\n    </tr>\n    <tr>\n      <th>14998</th>\n      <td>“Get to know yourself.You can’t improve upon s...</td>\n    </tr>\n    <tr>\n      <th>14999</th>\n      <td>“Once you know you love your job, never stop a...</td>\n    </tr>\n  </tbody>\n</table>\n<p>15000 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new['tweets']=clean","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"                                                 content  \\\n0      Be sure to tune in and watch Donald Trump on L...   \n1      Donald Trump will be appearing on The View tom...   \n2      Donald Trump reads Top Ten Financial Tips on L...   \n3      New Blog Post: Celebrity Apprentice Finale and...   \n4      \"My persona will never be that of a wallflower...   \n...                                                  ...   \n14995  W/a newly expanded 27 holes of golfing, Trump ...   \n14996  Thank you @ HauteLivingMag for naming @ TrumpD...   \n14997  As I predicted, Obama already caught lying on ...   \n14998  “Get to know yourself.You can’t improve upon s...   \n14999  “Once you know you love your job, never stop a...   \n\n                                                  tweets  \n0      sure tune watch donald trump late night david ...  \n1      donald trump appearing view tomorrow morning d...  \n2      donald trump read top ten financial tip late s...  \n3      new blog post celebrity apprentice finale less...  \n4      persona never wallflower rather build wall cli...  \n...                                                  ...  \n14995  w newly expanded 27 hole golfing trump intl pa...  \n14996  thank hautelivingmag naming trumpdoral 1 golf ...  \n14997  predicted obama already caught lying ocare enr...  \n14998  get know improve upon something understand ask...  \n14999  know love job never stop never give think like...  \n\n[15000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>tweets</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Be sure to tune in and watch Donald Trump on L...</td>\n      <td>sure tune watch donald trump late night david ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Donald Trump will be appearing on The View tom...</td>\n      <td>donald trump appearing view tomorrow morning d...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n      <td>donald trump read top ten financial tip late s...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n      <td>new blog post celebrity apprentice finale less...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\"My persona will never be that of a wallflower...</td>\n      <td>persona never wallflower rather build wall cli...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14995</th>\n      <td>W/a newly expanded 27 holes of golfing, Trump ...</td>\n      <td>w newly expanded 27 hole golfing trump intl pa...</td>\n    </tr>\n    <tr>\n      <th>14996</th>\n      <td>Thank you @ HauteLivingMag for naming @ TrumpD...</td>\n      <td>thank hautelivingmag naming trumpdoral 1 golf ...</td>\n    </tr>\n    <tr>\n      <th>14997</th>\n      <td>As I predicted, Obama already caught lying on ...</td>\n      <td>predicted obama already caught lying ocare enr...</td>\n    </tr>\n    <tr>\n      <th>14998</th>\n      <td>“Get to know yourself.You can’t improve upon s...</td>\n      <td>get know improve upon something understand ask...</td>\n    </tr>\n    <tr>\n      <th>14999</th>\n      <td>“Once you know you love your job, never stop a...</td>\n      <td>know love job never stop never give think like...</td>\n    </tr>\n  </tbody>\n</table>\n<p>15000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.tokenize import word_tokenize","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new['tokens']=df_new['tweets'].apply(word_tokenize)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"                                                 content  \\\n0      Be sure to tune in and watch Donald Trump on L...   \n1      Donald Trump will be appearing on The View tom...   \n2      Donald Trump reads Top Ten Financial Tips on L...   \n3      New Blog Post: Celebrity Apprentice Finale and...   \n4      \"My persona will never be that of a wallflower...   \n...                                                  ...   \n14995  W/a newly expanded 27 holes of golfing, Trump ...   \n14996  Thank you @ HauteLivingMag for naming @ TrumpD...   \n14997  As I predicted, Obama already caught lying on ...   \n14998  “Get to know yourself.You can’t improve upon s...   \n14999  “Once you know you love your job, never stop a...   \n\n                                                  tweets  \\\n0      sure tune watch donald trump late night david ...   \n1      donald trump appearing view tomorrow morning d...   \n2      donald trump read top ten financial tip late s...   \n3      new blog post celebrity apprentice finale less...   \n4      persona never wallflower rather build wall cli...   \n...                                                  ...   \n14995  w newly expanded 27 hole golfing trump intl pa...   \n14996  thank hautelivingmag naming trumpdoral 1 golf ...   \n14997  predicted obama already caught lying ocare enr...   \n14998  get know improve upon something understand ask...   \n14999  know love job never stop never give think like...   \n\n                                                  tokens  \n0      [sure, tune, watch, donald, trump, late, night...  \n1      [donald, trump, appearing, view, tomorrow, mor...  \n2      [donald, trump, read, top, ten, financial, tip...  \n3      [new, blog, post, celebrity, apprentice, final...  \n4      [persona, never, wallflower, rather, build, wa...  \n...                                                  ...  \n14995  [w, newly, expanded, 27, hole, golfing, trump,...  \n14996  [thank, hautelivingmag, naming, trumpdoral, 1,...  \n14997  [predicted, obama, already, caught, lying, oca...  \n14998  [get, know, improve, upon, something, understa...  \n14999  [know, love, job, never, stop, never, give, th...  \n\n[15000 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>tweets</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Be sure to tune in and watch Donald Trump on L...</td>\n      <td>sure tune watch donald trump late night david ...</td>\n      <td>[sure, tune, watch, donald, trump, late, night...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Donald Trump will be appearing on The View tom...</td>\n      <td>donald trump appearing view tomorrow morning d...</td>\n      <td>[donald, trump, appearing, view, tomorrow, mor...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n      <td>donald trump read top ten financial tip late s...</td>\n      <td>[donald, trump, read, top, ten, financial, tip...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n      <td>new blog post celebrity apprentice finale less...</td>\n      <td>[new, blog, post, celebrity, apprentice, final...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\"My persona will never be that of a wallflower...</td>\n      <td>persona never wallflower rather build wall cli...</td>\n      <td>[persona, never, wallflower, rather, build, wa...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14995</th>\n      <td>W/a newly expanded 27 holes of golfing, Trump ...</td>\n      <td>w newly expanded 27 hole golfing trump intl pa...</td>\n      <td>[w, newly, expanded, 27, hole, golfing, trump,...</td>\n    </tr>\n    <tr>\n      <th>14996</th>\n      <td>Thank you @ HauteLivingMag for naming @ TrumpD...</td>\n      <td>thank hautelivingmag naming trumpdoral 1 golf ...</td>\n      <td>[thank, hautelivingmag, naming, trumpdoral, 1,...</td>\n    </tr>\n    <tr>\n      <th>14997</th>\n      <td>As I predicted, Obama already caught lying on ...</td>\n      <td>predicted obama already caught lying ocare enr...</td>\n      <td>[predicted, obama, already, caught, lying, oca...</td>\n    </tr>\n    <tr>\n      <th>14998</th>\n      <td>“Get to know yourself.You can’t improve upon s...</td>\n      <td>get know improve upon something understand ask...</td>\n      <td>[get, know, improve, upon, something, understa...</td>\n    </tr>\n    <tr>\n      <th>14999</th>\n      <td>“Once you know you love your job, never stop a...</td>\n      <td>know love job never stop never give think like...</td>\n      <td>[know, love, job, never, stop, never, give, th...</td>\n    </tr>\n  </tbody>\n</table>\n<p>15000 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new['tokens'][90]","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"['melania',\n 'qvc',\n 'tomorrow',\n 'night',\n '9',\n 'p',\n 'et',\n 'introduce',\n 'beautiful',\n 'inspiring',\n 'melania',\n 'timepiece',\n 'fashion',\n 'jewelry',\n 'collection']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new['tokens'][90]","execution_count":50,"outputs":[{"output_type":"execute_result","execution_count":50,"data":{"text/plain":"['melania',\n 'qvc',\n 'tomorrow',\n 'night',\n '9',\n 'p',\n 'et',\n 'introduce',\n 'beautiful',\n 'inspiring',\n 'melania',\n 'timepiece',\n 'fashion',\n 'jewelry',\n 'collection']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"vect = CountVectorizer().fit(df_new['tokens'][90])\nbag_of_words = vect.transform(df_new['tokens'][90])\nsum_words = bag_of_words.sum(axis=0) ","execution_count":47,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum_words","execution_count":49,"outputs":[{"output_type":"execute_result","execution_count":49,"data":{"text/plain":"matrix([[1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1]], dtype=int64)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Get most Frequent Words.."},{"metadata":{"trusted":true},"cell_type":"code","source":"def most_freq_words(s, n=None):\n    vect = CountVectorizer().fit(s)\n    bag_of_words = vect.transform(s)\n    sum_words = bag_of_words.sum(axis=0) \n    freq = [(word, sum_words[0, idx]) for word, idx in vect.vocabulary_.items()]\n    freq =sorted(freq, key = lambda x: x[1], reverse=True)\n    return freq[:n]","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"most_freq_words([ word for tweet in df_new.tokens for word in tweet],20)","execution_count":38,"outputs":[{"output_type":"execute_result","execution_count":38,"data":{"text/plain":"[('realdonaldtrump', 2933),\n ('great', 1760),\n ('thanks', 1611),\n ('trump', 1552),\n ('obama', 926),\n ('barackobama', 798),\n ('thank', 667),\n ('good', 640),\n ('get', 610),\n ('like', 607),\n ('time', 603),\n ('people', 577),\n ('president', 568),\n ('donald', 555),\n ('would', 555),\n ('cont', 547),\n ('new', 540),\n ('think', 536),\n ('one', 511),\n ('job', 468)]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Least Frequent Words.."},{"metadata":{"trusted":true},"cell_type":"code","source":"def least_freq_words(s, n=None):\n    vect = CountVectorizer().fit(s)\n    bag_of_words = vect.transform(s)\n    sum_words = bag_of_words.sum(axis=0) \n    freq = [(word, sum_words[0, idx]) for word, idx in vect.vocabulary_.items()]\n    freq =sorted(freq, key = lambda x: x[1], reverse=False)\n    return freq[:n]","execution_count":41,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"least_freq_words([ word for tweet in df_new.tokens for word in tweet],20)","execution_count":42,"outputs":[{"output_type":"execute_result","execution_count":42,"data":{"text/plain":"[('wallflower', 1),\n ('cling', 1),\n ('tara', 1),\n ('conner', 1),\n ('achieves', 1),\n ('trumpative', 1),\n ('barnesandnoble', 1),\n ('precipice', 1),\n ('igoogle', 1),\n ('thoughtful', 1),\n ('fb', 1),\n ('url', 1),\n ('sf', 1),\n ('chronicle', 1),\n ('beckham', 1),\n ('britney', 1),\n ('inexplicable', 1),\n ('randal', 1),\n ('pinkett', 1),\n ('lieutenant', 1)]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new['tokens'][1]","execution_count":65,"outputs":[{"output_type":"execute_result","execution_count":65,"data":{"text/plain":"['donald',\n 'trump',\n 'appearing',\n 'view',\n 'tomorrow',\n 'morning',\n 'discus',\n 'celebrity',\n 'apprentice',\n 'new',\n 'book',\n 'think',\n 'like',\n 'champion']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cvn = CountVectorizer()\ndata_cvn = cvn.fit_transform([word.lower() for word in df_new['tokens'][1]])\ndata_dtmn = pd.DataFrame(data_cvn.toarray(), columns=cvn.get_feature_names())\ndata_dtmn","execution_count":59,"outputs":[{"output_type":"execute_result","execution_count":59,"data":{"text/plain":"    appearing  apprentice  book  celebrity  champion  discus  donald  like  \\\n0           0           0     0          0         0       0       1     0   \n1           0           0     0          0         0       0       0     0   \n2           1           0     0          0         0       0       0     0   \n3           0           0     0          0         0       0       0     0   \n4           0           0     0          0         0       0       0     0   \n5           0           0     0          0         0       0       0     0   \n6           0           0     0          0         0       1       0     0   \n7           0           0     0          1         0       0       0     0   \n8           0           1     0          0         0       0       0     0   \n9           0           0     0          0         0       0       0     0   \n10          0           0     1          0         0       0       0     0   \n11          0           0     0          0         0       0       0     0   \n12          0           0     0          0         0       0       0     1   \n13          0           0     0          0         1       0       0     0   \n\n    morning  new  think  tomorrow  trump  view  \n0         0    0      0         0      0     0  \n1         0    0      0         0      1     0  \n2         0    0      0         0      0     0  \n3         0    0      0         0      0     1  \n4         0    0      0         1      0     0  \n5         1    0      0         0      0     0  \n6         0    0      0         0      0     0  \n7         0    0      0         0      0     0  \n8         0    0      0         0      0     0  \n9         0    1      0         0      0     0  \n10        0    0      0         0      0     0  \n11        0    0      1         0      0     0  \n12        0    0      0         0      0     0  \n13        0    0      0         0      0     0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>appearing</th>\n      <th>apprentice</th>\n      <th>book</th>\n      <th>celebrity</th>\n      <th>champion</th>\n      <th>discus</th>\n      <th>donald</th>\n      <th>like</th>\n      <th>morning</th>\n      <th>new</th>\n      <th>think</th>\n      <th>tomorrow</th>\n      <th>trump</th>\n      <th>view</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,15000):\n    cvn = CountVectorizer()\n    data_cvn = cvn.fit_transform(df_new['tokens'][i])\n    data_dtmn = pd.DataFrame(data_cvn.toarray(), columns=cvn.get_feature_names())\n#     data_dtmn","execution_count":66,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"empty vocabulary; perhaps the documents only contain stop words","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-66-dbc8eb5e85d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcvn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata_cvn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcvn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdata_dtmn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_cvn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcvn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     data_dtmn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1220\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1148\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n\u001b[0m\u001b[1;32m   1151\u001b[0m                                  \" contain stop words\")\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"corpusn = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmn.transpose()))","execution_count":51,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'Dictionary' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-51-3a77af4288e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweets_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'Dictionary' is not defined"]}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}